"""íŠ¹í—ˆ PDF ê¸°ë°˜ ê²€ìƒ‰ì‹ ìƒì„± ë° Seed Recall ì¸¡ì • ë„êµ¬

Google Gemini 2.5 Proë¥¼ ì‚¬ìš©í•˜ì—¬ íŠ¹í—ˆ PDFë¥¼ ë¶„ì„í•˜ê³ ,
ìœ ì‚¬ íŠ¹í—ˆ ê²€ìƒ‰ì„ ìœ„í•œ ê²€ìƒ‰ì‹ì„ ìë™ ìƒì„±í•œ í›„,
ìƒì„±ëœ ê²€ìƒ‰ì‹ë“¤ì˜ ì„±ëŠ¥ì„ ì¸¡ì •í•©ë‹ˆë‹¤.

ì‚¬ìš© ì˜ˆì‹œ:
  # ê¸°ë³¸ ì‚¬ìš©ë²• (í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ë¡œë“œ)
  python patent_analyzer.py \
    --pdf patent.pdf \
    --prompt analyzer_prompt.txt \
    --output temp_results/analysis.json

  # ì „ì²´ Seed Recall ê³„ì‚° (ë” ì •í™•í•˜ì§€ë§Œ ì˜¤ë˜ ê±¸ë¦¼)
  python patent_analyzer.py \
    --pdf patent.pdf \
    --output temp_results/full_analysis.json \
    --full-recall

  # API í‚¤ë¥¼ ì§ì ‘ ì§€ì •
  python patent_analyzer.py \
    --pdf patent.pdf \
    --api-key YOUR_API_KEY \
    --output temp_results/results.json

  # ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ì™€ ìƒì„¸ ì˜µì…˜
  python patent_analyzer.py \
    --pdf patent.pdf \
    --prompt custom_prompt.txt \
    --output temp_results/custom_results.json \
    --max-results 10 \
    --delay 2.0

ì£¼ìš” ê¸°ëŠ¥:
- PDFë¥¼ Gemini APIì— ì§ì ‘ ì—…ë¡œë“œí•˜ì—¬ ë¶„ì„
- AI ê¸°ë°˜ ë‹¤ì¤‘ ê²€ìƒ‰ ì „ëµ ìƒì„±
- Google Patentsì—ì„œ ì‹¤ì œ ê²€ìƒ‰ ìˆ˜í–‰ ë° ê²°ê³¼ ìˆ˜ì§‘
- Seed Recall ê³„ì‚° (ì›ë³¸ íŠ¹í—ˆê°€ ê²€ìƒ‰ ê²°ê³¼ì— í¬í•¨ë˜ëŠ”ì§€)
- JSON/CSV í˜•íƒœì˜ ìƒì„¸í•œ ì„±ëŠ¥ ë³´ê³ ì„œ ìƒì„±

í•„ìˆ˜ ì„¤ì •:
1. pip install -r requirements.txt
2. Google AI Studioì—ì„œ API í‚¤ ë°œê¸‰
3. .env íŒŒì¼ì— GOOGLE_API_KEY ì„¤ì • ë˜ëŠ” --api-key ì‚¬ìš©
"""

import argparse
import asyncio
import json
import os
import re
import subprocess
import sys
import tempfile
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

import google.generativeai as genai
from dotenv import load_dotenv
from loguru import logger

# ê¸°ì¡´ downloader ì„í¬íŠ¸
sys.path.append(str(Path(__file__).parent))
from patent_downloader import GooglePatentsXHRDownloader, PatentSummary


def extract_patent_number_from_filename(pdf_path: Path) -> str:
    """PDF íŒŒì¼ëª…ì—ì„œ íŠ¹í—ˆë²ˆí˜¸ ì¶”ì¶œ (í™•ì¥ì ì œê±°)
    
    ì˜ˆ: US8771637B2.pdf â†’ US8771637B2
    """
    return pdf_path.stem


def normalize_patent_number(patent_number: str) -> str:
    """íŠ¹í—ˆë²ˆí˜¸ ì •ê·œí™” (ê³µë°±, ì‰¼í‘œ, í•˜ì´í”ˆ ì œê±° ë° ëŒ€ë¬¸ì ë³€í™˜)
    
    ì˜ˆ: "US 8,771,637 B2" â†’ "US8771637B2"
    """
    if not patent_number:
        return ""
    
    # ê³µë°±, ì‰¼í‘œ, í•˜ì´í”ˆ ì œê±° í›„ ëŒ€ë¬¸ì ë³€í™˜
    normalized = re.sub(r'[\s,\-]', '', patent_number).upper()
    return normalized


class PatentQueryGenerator:
    """íŠ¹í—ˆ PDF ê¸°ë°˜ ê²€ìƒ‰ì‹ ìƒì„± ë° ì„±ëŠ¥ ì¸¡ì • í´ë˜ìŠ¤"""
    
    def __init__(
        self,
        api_key: str,
        download_dir: Path,
        max_results: int = 10,
        delay: float = 1.0
    ):
        self.api_key = api_key
        self.download_dir = download_dir
        self.max_results = max_results
        self.delay = delay
        
        # Gemini ì„¤ì •
        genai.configure(api_key=api_key)
        self.model = genai.GenerativeModel("gemini-2.0-flash-exp")
        
        # Google Patents downloader ì´ˆê¸°í™”
        self.downloader = GooglePatentsXHRDownloader(
            download_dir=download_dir,
            headless=True,
            delay=delay,
            timeout=30
        )
        
    async def upload_pdf_to_gemini(self, pdf_path: Path) -> str:
        """PDF íŒŒì¼ì„ Gemini APIì— ì—…ë¡œë“œ"""
        logger.info(f"Uploading PDF to Gemini API: {pdf_path}")
        
        try:
            # íŒŒì¼ ì—…ë¡œë“œ
            uploaded_file = genai.upload_file(
                path=str(pdf_path),
                display_name=pdf_path.name
            )
            
            # ì—…ë¡œë“œ ì™„ë£Œ ëŒ€ê¸°
            while uploaded_file.state.name == "PROCESSING":
                await asyncio.sleep(1)
                uploaded_file = genai.get_file(uploaded_file.name)
            
            if uploaded_file.state.name == "FAILED":
                raise Exception(f"File upload failed: {uploaded_file.state}")
            
            logger.info(f"PDF uploaded successfully: {uploaded_file.name}")
            return uploaded_file.name
            
        except Exception as exc:
            logger.error(f"PDF upload failed: {exc}")
            raise
    
    async def generate_queries(
        self, 
        pdf_file_name: str, 
        prompt_template: str
    ) -> Dict[str, Any]:
        """Geminië¥¼ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ì‹ ìƒì„±"""
        logger.info("Generating search queries with Gemini...")
        
        try:
            # ì—…ë¡œë“œëœ íŒŒì¼ ê°ì²´ ê°€ì ¸ì˜¤ê¸°
            uploaded_file = genai.get_file(pdf_file_name)
            
            # Geminiì— í”„ë¡¬í”„íŠ¸ì™€ íŒŒì¼ ì „ì†¡
            response = self.model.generate_content([
                uploaded_file,
                prompt_template
            ])
            
            # JSON ì‘ë‹µ íŒŒì‹±
            response_text = response.text.strip()
            logger.debug(f"Gemini response: {response_text}")
            
            # JSON ì¶”ì¶œ (ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°)
            json_match = re.search(r'```json\n(.*?)\n```', response_text, re.DOTALL)
            if json_match:
                json_text = json_match.group(1)
            else:
                # ì½”ë“œ ë¸”ë¡ì´ ì—†ìœ¼ë©´ ì „ì²´ ì‘ë‹µì—ì„œ JSON ì°¾ê¸°
                json_text = response_text
            
            queries_data = json.loads(json_text)
            logger.info(f"Generated {len(queries_data.get('search_queries', []))} search queries")
            
            return queries_data
            
        except Exception as exc:
            logger.error(f"Query generation failed: {exc}")
            raise
    
    async def execute_searches(
        self, 
        queries_data: Dict[str, Any],
        target_patent: Optional[str] = None,
        full_recall: bool = False
    ) -> List[Dict[str, Any]]:
        """ìƒì„±ëœ ê²€ìƒ‰ì‹ë“¤ì„ ì‹¤í–‰í•˜ê³  ê²°ê³¼ ìˆ˜ì§‘"""
        logger.info(f"Executing search queries (full_recall={full_recall})...")
        
        # target_patent ì„¤ì • (early terminationìš©)
        if target_patent:
            self.downloader._target_patent = target_patent
            logger.info(f"Target patent for early termination: {target_patent}")
        
        search_results = []
        queries = queries_data.get("search_queries", [])
        
        for i, query_info in enumerate(queries, 1):
            query = query_info.get("query", "")
            strategy = query_info.get("strategy", f"Query {i}")
            
            logger.info(f"[{i}/{len(queries)}] Executing: {strategy}")
            logger.info(f"Query: {query}")
            
            try:
                # count-only ëª¨ë“œë¡œ ê²€ìƒ‰ ì‹¤í–‰ (full_recall ì˜µì…˜ í¬í•¨)
                saved_files, total_count, patents = await self.downloader.search_and_download(
                    query=query,
                    max_results=self.max_results,
                    count_only=True,
                    full_recall=full_recall
                )
                
                result = {
                    "query_index": i,
                    "strategy": strategy,
                    "query": query,
                    "expected_scope": query_info.get("expected_scope", "unknown"),
                    "total_results": total_count,
                    "parsed_results": len(patents),
                    "found_patents": [p.publication_number for p in patents if p.publication_number],
                    "success": True,
                    "error": None
                }
                
                logger.info(f"Results: {total_count} total, {len(patents)} parsed")
                if patents:
                    logger.info(f"Found patents: {[p.publication_number for p in patents[:3]]}")  # ì²˜ìŒ 3ê°œë§Œ ë¡œê·¸
                
            except Exception as exc:
                logger.error(f"Search failed: {exc}")
                result = {
                    "query_index": i,
                    "strategy": strategy,
                    "query": query,
                    "expected_scope": query_info.get("expected_scope", "unknown"),
                    "total_results": None,
                    "parsed_results": 0,
                    "found_patents": [],
                    "success": False,
                    "error": str(exc)
                }
            
            search_results.append(result)
            
            # ìš”ì²­ ê°„ ì§€ì—°
            if i < len(queries):
                await asyncio.sleep(self.delay)
        
        return search_results
    
    def calculate_seed_recall(
        self, 
        original_patent_number: str,
        search_results: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """íŒŒì¼ëª… ê¸°ë°˜ Seed Recall ê³„ì‚°"""
        logger.info(f"Calculating Seed Recall for patent: {original_patent_number}")
        
        # íŠ¹í—ˆë²ˆí˜¸ ì •ê·œí™”
        normalized_original = normalize_patent_number(original_patent_number)
        
        # ê° ê²€ìƒ‰ì‹ë³„ë¡œ ì›ë³¸ íŠ¹í—ˆ ë°œê²¬ ì—¬ë¶€ í™•ì¸
        query_recalls = []
        found_in_queries = 0
        
        for result in search_results:
            if not result["success"]:
                query_recalls.append({
                    "query_index": result["query_index"],
                    "strategy": result["strategy"], 
                    "found": False,
                    "reason": "Query failed"
                })
                continue
            
            found_patents = result.get("found_patents", [])
            normalized_found = [normalize_patent_number(p) for p in found_patents if p]
            
            is_found = normalized_original in normalized_found
            if is_found:
                found_in_queries += 1
                
            query_recalls.append({
                "query_index": result["query_index"],
                "strategy": result["strategy"],
                "found": is_found,
                "total_results": result["total_results"],
                "parsed_results": result["parsed_results"],
                "found_patents_sample": found_patents[:3] if found_patents else []
            })
            
            logger.info(f"Query {result['query_index']}: {'âœ… Found' if is_found else 'âŒ Not found'} - {result['parsed_results']} results")
        
        # í†µê³„ ê³„ì‚°
        total_queries = len(search_results)
        successful_queries = len([r for r in search_results if r["success"]])
        avg_total_results = sum(
            r["total_results"] or 0 for r in search_results if r["success"]
        ) / max(successful_queries, 1)
        avg_parsed_results = sum(
            r["parsed_results"] for r in search_results
        ) / max(total_queries, 1)
        
        seed_recall_rate = found_in_queries / total_queries if total_queries > 0 else 0
        
        return {
            "original_patent": original_patent_number,
            "normalized_patent": normalized_original,
            "total_queries": total_queries,
            "successful_queries": successful_queries,
            "success_rate": successful_queries / total_queries if total_queries > 0 else 0,
            "avg_total_results": round(avg_total_results, 1),
            "avg_parsed_results": round(avg_parsed_results, 1),
            "seed_recall_rate": seed_recall_rate,
            "queries_found_patent": found_in_queries,
            "query_details": query_recalls
        }
    
    async def generate_and_evaluate(
        self, 
        pdf_path: Path,
        prompt_template: str
    ) -> Dict[str, Any]:
        """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰: PDF ë¶„ì„ â†’ ê²€ìƒ‰ì‹ ìƒì„± â†’ ê²€ìƒ‰ ì‹¤í–‰ â†’ í‰ê°€"""
        logger.info(f"Starting analysis pipeline for: {pdf_path}")
        
        # 1. PDF ì—…ë¡œë“œ
        uploaded_file_name = await self.upload_pdf_to_gemini(pdf_path)
        
        try:
            # 2. ê²€ìƒ‰ì‹ ìƒì„±
            queries_data = await self.generate_queries(uploaded_file_name, prompt_template)
            
            # 3. ê²€ìƒ‰ ì‹¤í–‰ 
            original_patent_from_file = extract_patent_number_from_filename(pdf_path)
            search_results = await self.execute_searches(
                queries_data, 
                target_patent=original_patent_from_file,
                full_recall=getattr(self, 'full_recall_mode', False)
            )
            
            # 4. ì„±ëŠ¥ í‰ê°€
            performance = self.calculate_seed_recall(original_patent_from_file, search_results)
            
            # 5. ê²°ê³¼ ì¢…í•©
            final_result = {
                "metadata": {
                    "pdf_file": str(pdf_path),
                    "analysis_time": datetime.now().isoformat(),
                    "gemini_file_name": uploaded_file_name
                },
                "patent_info": queries_data.get("patent_info", {}),
                "search_results": search_results,
                "performance_summary": performance
            }
            
            return final_result
            
        finally:
            # ì—…ë¡œë“œëœ íŒŒì¼ ì •ë¦¬
            try:
                genai.delete_file(uploaded_file_name)
                logger.info("Cleaned up uploaded file")
            except Exception as exc:
                logger.warning(f"Failed to cleanup uploaded file: {exc}")


def load_prompt_template(prompt_path: Path) -> str:
    """í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ íŒŒì¼ ë¡œë“œ"""
    if not prompt_path.exists():
        raise FileNotFoundError(f"Prompt file not found: {prompt_path}")
    
    return prompt_path.read_text(encoding="utf-8")


def save_results(results: Dict[str, Any], output_path: Path) -> None:
    """ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    
    logger.info(f"Results saved to: {output_path}")


def setup_api_key(args) -> str:
    """API í‚¤ ì„¤ì • ë° ë°˜í™˜"""
    # 1. ëª…ë ¹í–‰ ì¸ì ìš°ì„ 
    if args.api_key:
        return args.api_key
    
    # 2. í™˜ê²½ë³€ìˆ˜ì—ì„œ ë¡œë“œ
    load_dotenv()
    api_key = os.getenv("GOOGLE_API_KEY")
    
    if not api_key:
        raise ValueError(
            "Google API key not found. Please provide it via:\n"
            "1. --api-key argument\n"
            "2. GOOGLE_API_KEY environment variable\n"
            "3. .env file with GOOGLE_API_KEY=your_key"
        )
    
    return api_key


def build_cli_parser() -> argparse.ArgumentParser:
    parser = argparse.ArgumentParser(
        description="íŠ¹í—ˆ PDF ê¸°ë°˜ ê²€ìƒ‰ì‹ ìƒì„± ë° ì„±ëŠ¥ ì¸¡ì •"
    )
    
    parser.add_argument(
        "--pdf",
        type=Path,
        required=True,
        help="ë¶„ì„í•  íŠ¹í—ˆ PDF íŒŒì¼"
    )
    
    parser.add_argument(
        "--prompt",
        type=Path,
        default=Path("analyzer_prompt.txt"),
        help="ê²€ìƒ‰ì‹ ìƒì„± í”„ë¡¬í”„íŠ¸ íŒŒì¼ (ê¸°ë³¸ê°’: analyzer_prompt.txt)"
    )
    
    parser.add_argument(
        "--output",
        type=Path,
        default=Path("temp_results/results.json"),
        help="ê²°ê³¼ ì €ì¥ íŒŒì¼ (ê¸°ë³¸ê°’: temp_results/results.json)"
    )
    
    parser.add_argument(
        "--api-key",
        help="Google Gemini API í‚¤ (í™˜ê²½ë³€ìˆ˜ GOOGLE_API_KEY ì‚¬ìš© ê°€ëŠ¥)"
    )
    
    parser.add_argument(
        "--download-dir",
        type=Path,
        default=Path("./temp_downloads"),
        help="ì„ì‹œ ë‹¤ìš´ë¡œë“œ ë””ë ‰í„°ë¦¬ (ê¸°ë³¸ê°’: ./temp_downloads)"
    )
    
    parser.add_argument(
        "--max-results",
        type=int,
        default=10,
        help="ê²€ìƒ‰ ì‹œ ìµœëŒ€ ê²°ê³¼ ìˆ˜ (ê¸°ë³¸ê°’: 10)"
    )
    
    parser.add_argument(
        "--delay",
        type=float,
        default=1.5,
        help="ê²€ìƒ‰ ìš”ì²­ ê°„ ì§€ì—° ì‹œê°„(ì´ˆ) (ê¸°ë³¸ê°’: 1.5)"
    )
    
    parser.add_argument(
        "--full-recall",
        action="store_true",
        help="ì „ì²´ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ìˆ˜ì§‘í•˜ì—¬ ì •í™•í•œ Seed Recall ê³„ì‚° (ë” ì˜¤ë˜ ê±¸ë¦¼)"
    )
    
    return parser


async def main() -> int:
    parser = build_cli_parser()
    args = parser.parse_args()
    
    # ì…ë ¥ ê²€ì¦
    if not args.pdf.exists():
        logger.error(f"PDF file not found: {args.pdf}")
        return 1
    
    # API í‚¤ ì„¤ì •
    try:
        api_key = setup_api_key(args)
    except ValueError as exc:
        logger.error(str(exc))
        return 1
    
    # í”„ë¡¬í”„íŠ¸ ë¡œë“œ
    try:
        prompt_template = load_prompt_template(args.prompt)
    except FileNotFoundError as exc:
        logger.error(str(exc))
        return 1
    
    # ë‹¤ìš´ë¡œë“œ ë””ë ‰í„°ë¦¬ ìƒì„±
    args.download_dir.mkdir(parents=True, exist_ok=True)
    
    # ë¶„ì„ ì‹¤í–‰
    generator = PatentQueryGenerator(
        api_key=api_key,
        download_dir=args.download_dir,
        max_results=args.max_results,
        delay=args.delay
    )
    generator.full_recall_mode = args.full_recall
    
    try:
        results = await generator.generate_and_evaluate(
            pdf_path=args.pdf,
            prompt_template=prompt_template
        )
        
        # ê²°ê³¼ ì €ì¥
        save_results(results, args.output)
        
        # ìš”ì•½ ì¶œë ¥
        performance = results["performance_summary"]
        patent_info = results["patent_info"]
        
        recall_mode = "ì „ì²´ ê²°ê³¼" if args.full_recall else "ë¶€ë¶„ ê²°ê³¼"
        print("\n" + "="*70)
        print(f"ğŸ” íŠ¹í—ˆ ê²€ìƒ‰ì‹ ìƒì„± ë° Seed Recall ë¶„ì„ ì™„ë£Œ ({recall_mode})")
        print("="*70)
        print(f"ğŸ“„ ë¶„ì„ ëŒ€ìƒ: {patent_info.get('title', 'Unknown')}")
        print(f"ğŸ”¢ íŒŒì¼ íŠ¹í—ˆë²ˆí˜¸: {performance['original_patent']}")
        print(f"ğŸ“Š ìƒì„±ëœ ê²€ìƒ‰ì‹: {performance['total_queries']}ê°œ")
        print(f"âœ… ì„±ê³µì  ê²€ìƒ‰: {performance['successful_queries']}ê°œ ({performance['success_rate']:.1%})")
        print(f"ğŸ“ˆ í‰ê·  ê²€ìƒ‰ ê²°ê³¼: {performance['avg_total_results']:.0f}ê±´")
        print()
        print("ğŸ¯ Seed Recall ê²°ê³¼:")
        print(f"   ğŸ“ ì›ë³¸ íŠ¹í—ˆ ë°œê²¬ìœ¨: {performance['seed_recall_rate']:.1%} ({performance['queries_found_patent']}/{performance['total_queries']})")
        
        # ê° ê²€ìƒ‰ì‹ë³„ ìƒì„¸ ê²°ê³¼
        for detail in performance.get('query_details', []):
            status = "âœ…" if detail['found'] else "âŒ"
            if 'reason' in detail:
                print(f"   {status} Query {detail['query_index']}: {detail['reason']}")
            else:
                print(f"   {status} Query {detail['query_index']}: {detail.get('total_results', 0)}ê±´ ì¤‘ {detail.get('parsed_results', 0)}ê±´ íŒŒì‹±")
        
        print()
        print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥: {args.output}")
        print("="*70)
        
        return 0
        
    except Exception as exc:
        logger.error(f"Analysis failed: {exc}")
        return 1


if __name__ == "__main__":
    asyncio.run(main())